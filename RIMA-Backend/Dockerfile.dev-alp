# FROM brunneis/python:3.8.3-ubuntu-20.04
FROM python:3.7-slim

EXPOSE 8000

WORKDIR /app

RUN apt-get update -y
RUN apt-get install -y python-dev python3-dev
RUN apt-get -y install default-libmysqlclient-dev automake make gcc g++ curl

### Install JAVA
RUN set -eux; \
     curl -Lso /tmp/openjdk.tar.gz https://github.com/AdoptOpenJDK/openjdk10-releases/releases/download/jdk-10.0.2%2B13/OpenJDK10_x64_Linux_jdk-10.0.2%2B13.tar.gz; \
     mkdir -p /opt/java/openjdk; \
     cd /opt/java/openjdk; \
     tar -xf /tmp/openjdk.tar.gz; \
     jdir=$(dirname $(dirname $(find /opt/java/openjdk -name javac))); \
     mv ${jdir}/* /opt/java/openjdk; \
     rm -rf ${jdir} /tmp/openjdk.tar.gz;

ENV JAVA_HOME=/opt/java/openjdk \
     PATH="/opt/java/openjdk/bin:$PATH"

RUN useradd -m app
USER app

ENV  PYTHONUNBUFFERED 1
ENV  PATH "$PATH:/app/.local/bin"

COPY requirements-docker.txt .

RUN python3 -m pip install --upgrade pip

RUN pip3 install --no-cache-dir --user -r requirements-docker.txt

RUN python3 -m spacy download en &&\
     python3 -c "import nltk;nltk.download('stopwords')" &&\
     python3 -c "import nltk;nltk.download('punkt')" &&\
     python3 -c "import nltk;nltk.download('sentiwordnet')"

COPY . .

# Download stanfordcorenlp
# RUN wget http://nlp.stanford.edu/software/stanford-corenlp-full-2018-02-27.zip -P /app/interests/Keyword_Extractor/Algorithms/embedding_based
# RUN unzip /app/interests/Keyword_Extractor/Algorithms/embedding_based/stanford-corenlp-latest.zip
# RUN rm /app/interests/Keyword_Extractor/Algorithms/embedding_based/stanford-corenlp-latest.zip

# Download msmarco
# RUN mkdir transformers
# RUN wget https://uni-duisburg-essen.sciebo.de/s/z1k3w8Oxb8RRd4M/download -P /app/transformers
# RUN unzip /app/transformers/msmarco.zip
# RUN rm /app/transformers/msmarco.zip

# RUN wget https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5 -P /app/interests/Keyword_Extractor/Algorithms/embedding_based/auxiliary_data
